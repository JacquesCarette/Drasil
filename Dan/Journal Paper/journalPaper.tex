\documentclass[format=acmsmall, review=false, screen=true]{acmart}

\usepackage{booktabs} % For formal tables
\usepackage{tikz}
\usetikzlibrary{positioning,fit,calc,shapes,shadows,arrows}
\usepackage{forest}
\usetikzlibrary{arrows.meta}
\usepackage[ruled]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}
\usepackage{hyperref}

% Metadata Information
\acmJournal{TOSEM}
%\acmVolume{}
%\acmNumber{}
%\acmArticle{}
%\acmYear{}
%\acmMonth{}
\copyrightyear{2018}
%\acmArticleSeq{9}

% Copyright
%\setcopyright{acmcopyright}
\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
\acmDOI{0000001.0000001}

% Paper history
%\received{February 2007}
%\received[revised]{March 2009}
%\received[accepted]{June 2009}

\newcommand{\dl}{drasil-lang}
\newcommand{\dc}{drasil-code}
\newcommand{\dd}{drasil-data}
\newcommand{\de}{drasil-example}

\newcommand{\edl}{\emph{\dl}}
\newcommand{\edc}{\emph{\dc}}
\newcommand{\edd}{\emph{\dd}}
\newcommand{\ede}{\emph{\de}}

%% Comments
\newif\ifcomments\commentstrue

\ifcomments
\newcommand{\authornotes}[3]{\textcolor{#1}{[#3 ---#2]}}
\newcommand{\todo}[1]{\textcolor{red}{[TODO: #1]}}
\else
\newcommand{\authornotes}[3]{}
\newcommand{\todo}[1]{}
\fi

\newcommand{\wss}[1]{\authornotes{blue}{SS}{#1}}
\newcommand{\jc}[1]{\authornotes{red}{JC}{#1}}

% Document starts
\begin{document}

%%%%%%%%%%%%%%%%%%%%%
% Tikz Styles
\tikzstyle{class}=[rectangle, draw=black, rounded corners, fill=white!40, drop 
shadow,
text centered, anchor=north, text=black, text width=3cm]
\tikzstyle{myarrow}=[->, >=triangle 90, thick]
%%%%%%%%%%%%%%%%%%%%%

% Title portion. Note the short title for running heads
\title[headertitle]{TITLE}

\author{Dan Szymczak}
%\orcid{1234-5678-9012-3456}
\affiliation{%
  \institution{McMaster University}
  \streetaddress{1280 Main St. W.}
  \city{Hamilton}
  \state{ON}
  \postcode{L8S 4K1}
  \country{Canada}}
\email{szymczdm@mcmaster.ca}
\author{Jacques Carette}
%\affiliation{%
%  \institution{Inria Paris-Rocquencourt}
%  \city{Rocquencourt}
%  \country{France}
%}
%\email{beranger@inria.fr}
\author{Spencer Smith}
%\affiliation{%
% \institution{Rajiv Gandhi University}
% \streetaddress{Rono-Hills}
% \city{Doimukh}
% \state{Arunachal Pradesh}
% \country{India}}
%\email{aprna_patel@rguhs.ac.in}
%\author{Huifen Chan}
%\affiliation{%
%  \institution{Tsinghua University}
%  \streetaddress{30 Shuangqing Rd}
%  \city{Haidian Qu}
%  \state{Beijing Shi}
%  \country{China}
%}
%\email{chan0345@tsinghua.edu.cn}
%\author{Ting Yan}
%\affiliation{%
%  \institution{Eaton Innovation Center}
%  \city{Prague}
%  \country{Czech Republic}}
%\email{yanting02@gmail.com}
%\author{Tian He}
%\affiliation{%
%  \institution{University of Virginia}
%  \department{School of Engineering}
%  \city{Charlottesville}
%  \state{VA}
%  \postcode{22903}
%  \country{USA}
%}
%\affiliation{%
%  \institution{University of Minnesota}
%  \country{USA}}
%\email{tinghe@uva.edu}
%\author{Chengdu Huang}
%\author{John A. Stankovic}
%\author{Tarek F. Abdelzaher}
%\affiliation{%
%  \institution{University of Virginia}
%  \department{School of Engineering}
%  \city{Charlottesville}
%  \state{VA}
%  \postcode{22903}
%  \country{USA}
%}


\begin{abstract}

CONTEXT: Software (re-)certification requires the creation and maintenance of
many different software artifacts. Manually creating and maintaining \wss{and
reusing?} them is tedious and costly. \wss{and error prone}

OBJECTIVE: Improve software (re-)certification efforts by automating as much of
the artifact creation process as possible, while maintaining full traceability
within -- and between -- artifacts.  %DS Secondary objective -> Knowledge reuse 
%-- Don't know if I want
% to focus here as it muddies the waters.

METHOD: %Use grounded theory in the creation of a tool for software artifact
%generation. 
Start by analyzing the artifacts themselves from several case 
studies to understand what (semantically) is being said in each.
Capture the underlying knowledge and apply transformations to create each of 
the requisite artifacts through a generative approach.  

RESULTS: Case studies -- GlassBR to show capture and transformation. SWHS and
NoPCM for reuse (Something about Kolmogorov complexity / MDL here?).
% Moved from Method:
Captured knowledge can 
be re-used across projects as it represents the ``science''. Maintenance
involves updating the captured knowledge or transformations as necessary.
%Moved from Objective:
Creation of our tool -- Drasil -- facilitates this automation process using a 
knowledge-based approach to Software Engineering.  \wss{Maybe add something
  about the infrastructure now being in place to reuse/grow the scientific and
  computing knowledge base to cover new case studies?  It would be nice if we
  could make the connection between Drasil's knowledge and existing scientific
  knowledge ontologies, but maybe it is too early for that connection?}

CONCLUSIONS: With good tool support and a front-loaded time investment, we can 
automate the generation of software artifacts required for certification. 
(fill in later)?????

\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
%\begin{CCSXML}
%<ccs2012>
% <concept>
%  <concept_id>10010520.10010553.10010562</concept_id>
%  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%  <concept_significance>500</concept_significance>
% </concept>
% <concept>
%  <concept_id>10010520.10010575.10010755</concept_id>
%  <concept_desc>Computer systems organization~Redundancy</concept_desc>
%  <concept_significance>300</concept_significance>
% </concept>
% <concept>
%  <concept_id>10010520.10010553.10010554</concept_id>
%  <concept_desc>Computer systems organization~Robotics</concept_desc>
%  <concept_significance>100</concept_significance>
% </concept>
% <concept>
%  <concept_id>10003033.10003083.10003095</concept_id>
%  <concept_desc>Networks~Network reliability</concept_desc>
%  <concept_significance>100</concept_significance>
% </concept>
%</ccs2012>
%\end{CCSXML}

%\ccsdesc[500]{Computer systems organization~Embedded systems}
%\ccsdesc[300]{Computer systems organization~Redundancy}
%\ccsdesc{Computer systems organization~Robotics}
%\ccsdesc[100]{Networks~Network reliability}

%
% End generated code
%


\keywords{??}


\maketitle

% The default list of authors is too long for headers.
\renewcommand{\shortauthors}{D.\ Szymczak et al.}
\newcommand{\fgr}{\textcolor{red}{!FIGURE!}}
\section{Introduction}\label{S:Intro}

Writing non-executable software artifacts (requirements and design documents,
verification \& validation plans, etc.) can be tedious work, but is 
ultimately necessary when attempting to certify software. 
Similarly, maintenance of these artifacts, as necessary for re-certification as 
improvements are made, typically requires a large time investment.

Why, in a world of software tools, do we continue to undertake these
efforts manually? Literate programming had the right idea, but was too heavily 
focused on code.

We want to aid software (re-)certification efforts by automating as much of the 
artifact creation process as possible. By generating our software artifacts -- 
including code -- in the right way, we can implement changes much more quickly 
and easily for a modest up-front time investment. By front-loading the costs of 
maintenance and rolling them into the development cycle, we can save time and 
money in the long run.

%DS Maybe throw in a figure here to show off a bunch of common artifacts.

%DS Should everything after this point go into Background? Maybe not
\subsection{Software (Re-)certification}

When we talk about software certification, we are specifically discussing the 
goal of determining ``based on the principles of science, engineering and 
measurement theory, whether an artifact satisfies accepted, well defined and 
measurable criteria''~\cite{HatcliffEtAl2009}. Essentially, we are ensuring that 
software, or some piece of it, performs a given task to within an acceptable 
standard and can potentially be reused in other systems.

Software certification is necessary by law in certain fields. This is 
particularly evident in safety-critical applications such as control systems 
for nuclear power plants or X-ray machines. 

Different certifying bodies exist across domains and each has their own list of 
requirements to satisfy for certifying software. Looking at some 
examples \cite{CSA1999,CSA2009,CDRH2002,FDA2014} there are many pieces
of requisite documentation including, but not limited to:

\begin{itemize}
\item Problem definition
\item Theory manual
\item Requirements specification
\item Design description
\item Verification and Validation (V\&V) report
\end{itemize}

We should keep in mind that we require full traceability -- inter- and 
intra-artifact -- of the knowledge contained within these artifacts. That is, 
we should be able to find an explicit link between our problem definition and 
theory manual, down to our requirements, design, and other development planning 
artifacts. From there, we should be able to continue through our proposed 
verification and validation plans, and should eventually end up in the V\&V 
report.

%DS rework the following paragraph
Ensuring this traceability and, in fact, getting anything certified has many 
costs associated with it. There is a massive time investment, fees, and costs 
associated with contracting out a third-party verifier. Overall it is a 
very expensive process.

Re-certification of software following any change, no matter how minor, %DS keep?
incurs a similar level of costs; all the artifacts must be updated to 
reflect the new change, and everything must be re-checked and verified to 
ensure no new errors have been introduced. We have an implicit burden of 
ensuring the consistency of related information across our artifacts.

We intend to alleviate some of this cost-burden through a strategic, generative 
approach to Software Engineering (SE). With the automated generation of 
artifacts we can ensure they are \emph{consistent by construction}, implement 
changes 
quickly, and automatically update relevant and/or dependent artifacts.

\subsection{Scope} %DS Should this be here? Maybe, as long as the above clarifies the problem.

- Scientific Computing Software
- Why? Many highly specialized SCS require certification. Ex. Control sfwr 
in nuclear power, x-ray machines, and other safety-critical contexts.
- Well understood domain -> theories underpinning the work being done.

\wss{My suggestion is to stop writing Section 1 for now and focus on Sections 5
	and 6.  Section 1 is a good start, but it feels like we need more current
	information on MDL.  We might also want more information on scientific
	knowledge ontologies.}


\section{Background}

Reducing the costs of (re-)certification efforts and automating the generation of software artifacts has been attempted in differing scopes by many others. We look to them for insight and in an attempt to combine the fruits of their labours into something more versatile.

In this section we will explore previous efforts in automating software artifact generation, as well as take a look at the current state of Model Driven Engineering and scientific knowledge ontologies.

\subsection{Software Artifact Reuse and Generation} %DS Is this subsect necessary?

Previous attempts at generating software artifacts were primarily focused on artifact reuse. One aim of these approaches was to remove the burden of replicating some artifacts.

We will start by looking at Compendia~\cite{GentlemanAndLang} 

Previous attempts at automating / reducing the artifact burden.

- Compendia - Trying to solve the problem of reproducibility 
%DS or whichever appropriate R goes here -- see Gentleman & Lang
  - Fits with goals of certification
  - focused on good science and being able to re-run experiments exactly
  - Not focused on DDD or its benefits, moreso 

- Previous attempts at automatically generating documentation
  - LP, tools like javadoc, Haddock, etc.
  - Too code-centric!
  - Comments and code still need to be updated in parallel, albeit to a lesser
    extent in some cases
  - In general, fairly rigidly structured output (you don't have much say on
    how it looks, only what information should be included and, sometimes, where
  - Finish with a focus on the good stuff:
    - Identified the need for good documentation
    - Keeps docs and code in the same place
        - Easier to manually maintain consistency and apply updates
- One other problem we've identified:
  - common underlying knowledge between projects is duplicated as there is no
   real cross-project reuse mechanism in place with these tools.

%DS - Really need an intro to the basics of grounded theory here, for section 
%3.1 (S:IntroCases) and subsequently 4.2 (S:KReUse)

\wss{Should MDL show up here?}

\section{A rational analysis of software artifacts}

- This section exists to show how we get from problem to solution.

\subsection{Introducing our case studies}
\label{S:IntroCases}

To understand exactly what we are looking at in our software artifacts, we will 
now introduce the case studies that have driven the development of the Drasil 
framework.

%DS Use a style similar to the Materials paper for introducing case studies 
%here.

- We introduce our case studies in a bit more depth here
	- GlassBR - what it's for, if it'll
	- SWHS and NoPCM - Software family members with a twist.
	- The rest (tiny, Gamephysics, and SSP) for additional examples and to give 
	us a bit more credibility in our analysis.
- Looking for commonalities between types of artifacts and what they are really 
saying.
- An obvious commonality across many projects in SCS -- SI and derived Units.

\subsection{Common software artifacts}



- Compare and contrast different software artifacts.
	- SRS vs. detailed design vs. code
	- same knowledge, different 'views'
	- only some of that knowledge is necessarily relevant in those views
	- \fgr: SRS \& DD showing the same piece of knowledge \label{Fig:SRSDDComp}
	in diff contexts. Use a few different \fgr here.
	- \fgr: Attempt to show generalized overlap via Venn diagram?

\subsection{Emerging structures} 
%DS want to fit this into the analysis but it would make more sense --after-- 
%the intro to KBSE
\label{S:KnowStruct}

- As shown above, 

In the common software artifacts we see different ways of representing what 
are, semantically, the same things (for example, see 
Figure~\ref{Fig:SRSDDComp}). We are really seeing the pieces of underlying 
knowledge that have been composed from a variety of components. Each component 
tells us something about one aspect of that piece of knowledge. Particularly, 
they give examples of how we can transform, or view, the same semantic 
knowledge in different contexts.

\begin{figure}
%GLASSBR DD here with code example, possible it might be useful earlier.
\caption{Data Definition for !FIXME! from GlassBR SRS}
\label{Fig:GlassBRDDSRS}
\end{figure}

\begin{figure}
%Fig goes here. Or lsting
\caption{Data Definition code from GlassBR implementation}
\label{Fig:GlassBRDDCode}
\end{figure}

If we take a look at one particular example across artifacts from GlassBR 
(Figures~\ref{Fig:GlassBRDDSRS},\ref{Fig:GlassBRDDCode}), we can see that it is 
an aggregation of the following components:

\begin{itemize}
\item Unique Identifier (label)
\item Symbolic (theory) representation
\item Symbolic (implementation) representation
\item Concise natural language description (a term)
\item Verbose natural language description (a definition)
\item Equation 
\item Constraints %(Really relevant. Again show \fgr as math and code)
\item Units? %DS If applicable in the example?
\end{itemize}

The unique identifier is fairly straightforward (!FIXME id!), it is just a 
label that we associate with this particular piece of knowledge and nothing 
else. The symbolic representations are just the symbols we use when referring 
to this particular quantity in an equation (theory) or code (implementation) 
context. Our natural language descriptions are terms and their corresponding 
definitions (!FIXME! and !FIXME! respectively for this example). 

We also have a defining equation, which incorporates the symbolic 
representation for various other pieces of knowledge and relates them to
!FIXME name!. Similarly, we have constraints which are just relationships which 
must be maintained between !NAME! and some other quantities. Lastly, we have 
the units which our quantity is measured in, which are derived from the 
fundamental !SI UNITS!. %!FILL IN?!

	%DS (not sure which yet, probably something big -- like a quantity or 
	%bigger; maybe a DD or TM?).
	% Working from TM or DD as an example

Similar examples of knowledge crop up over all the artifacts. Some have the 
same depth of information, whereas others do not. Regardless, all of our 
knowledge shares some components in common. We will always have a label, and 
usually a term and definition. Depending on what we're looking at, there may 
not be a symbolic representation, or perhaps we have a quantity that is 
unit-less. These special cases help us see the underlying root structure from 
which our knowledge buds. %DS Tree metaphor! Wooo!

-Discuss the breakdown of knowledge into classes. Refer to 
Table~\ref{Tab:KnowledgeClasses} for more.  \wss{This table looks like a good
  way to summarize this information to me.}

\begin{table}
\caption{Knowledge Classes}
\label{Tab:KnowledgeClasses}
\begin{tabular}[]{ l | l | l | l | l | l | l | l | l}
Knowledge Class & ID & Term & Abbreviation & Definition & Symbol & 
Equation & Constraints & Units \\

			\hline{} & & & & & & & & \\
Labeled & X & & & & & & &\\
			\hline{} & & & & & & & &  \\
Named Idea & X & X & O & & & & &\\
		  	\hline{} & & & & & & & & \\
Common Idea & X & X & X & & & & &\\
			\hline{} & & & & & & & &\\
Concept & X & X & X & X & & & &\\
%TODO: Finish filling in
\end{tabular}

Legend: X - Mandatory; O - Optional

\end{table}

\section{Knowledge-Based Software Engineering (KBSE)}
\label{S:KBSE}

Knowledge-Based Software Engineering (KBSE) was originally defined as an
``engineering discipline that includes the integration of knowledge into 
software systems in order to solve complex problems, which would normally 
require rather high level of human expertise''~\cite{FeigenbaumAndMcCorduck1983}.
This is a solid definition, provided we understand what ``knowledge'' is. So 
then, what exactly is knowledge?

Knowledge ``presents understanding of a subject area. It includes concepts and 
facts ... as well as relations ... and mechanisms for how to combine them to 
solve problems in that area''~\cite{Durkin1994}.

For our purposes, we extend and tighten this definition to include the 
additional constraint that a piece of knowledge has a structured encoding, as 
opposed to natural language encoding, which then allows it to be automatically 
reused. For example, the first law of thermodynamics is a piece of knowledge 
that can be simply expressed as ``total energy within a closed system must be 
conserved'', but this is not a structured encoding. One such encoding would 
allow us to view the knowledge in those relatively simple terms, or just as 
easily, we could view it as:
\begin{equation*}
\Delta{}U = Q - W
\end{equation*}
where we define a \emph{closed system} as one which cannot exchange matter with 
its surroundings, but energy can be transferred. $\Delta{}U$ is then the change 
in internal energy of a closed system, $Q$ is the amount of energy supplied to 
the system, and $W$ is the amount of energy lost to the system's surroundings 
as a result of work.

%\wss{What are you trying to say with this equation?  I think I like where you
%  are going, but this equation will need significantly more explanation to make
%  this work.  You need to say what $U$, $Q$ and $W$ represent.  You would also
%  need to define closed system.  Maybe we can use an example that has already
%  been worked out in our examples, like the conservation of thermal energy?}
Regardless of our view, we have not changed the underlying structured knowledge 
encoding -- we merely project out what is relevant to our current audience.

For our KBSE approach to succeed, there are two major requirements. First off, 
we must capture the underlying knowledge in a meaningful way that can be reused 
across artifacts. We want a single source for our knowledge, regardless where 
it ends up or how it is viewed. This allows us, using the right 
transformations, to automatically generate our software artifacts from the 
underlying knowledge-base.

The second requirement is that we restrict our scope to well-understood domains 
as we need a solid theoretical underpinning. Both mathematics and the physical 
sciences are good examples of well-understood domains as the knowledge has 
already been formalized and, to an extent, structured. These are also good 
candidate domains since we need to explain the underlying knowledge to 
computers in a nontrivial way, which from our experience, is harder than it 
sounds.

With that in mind, we have decided to restrict our focus to KBSE for Scientific 
Computing Software (SCS) as it is a field rich in knowledge we can use.

\subsection{Capturing Knowledge}
\label{S:KnowCapt}

From our work in Section~\ref{S:KnowStruct} we can create a knowledge-capture 
mechanism for encoding the requisite underlying science into a machine-usable 
form. By laying out the structure, we can see which information must be 
captured for each piece of knowledge.

Different types of information are required for encoding each of the various 
pieces of knowledge we intend to use. Some types of knowledge lack specific 
information bindings, for example a \emph{named idea} does not necessarily have 
a symbol associated with it, however, a \emph{quantity} \emph{must} have a 
symbol alongside its \emph{term} -- the fundamental information in a named idea.

We borrow, and expand, the idea of \emph{Chunks} from Literate Programming 
(LP)~\cite{Knuth1984} to facilitate our knowledge-capture. A chunk in its most 
rudimentary sense is simply a labeled piece of information. Given our 
understanding of how the knowledge should be structured, we have created a 
hierarchy of classes built up from the simplest of chunks, to fulfill our 
knowledge-capture requirements. This hierarchy as implemented in Drasil can be 
seen in Figure~\ref{Fig:ChunkHierarchy}. It mimics the structure mentioned in 
Section~\ref{S:KnowStruct}. We will delve deeper into the specifics of our 
hierarchy in Section~\ref{S:Drasil}.

\begin{figure}
\begin{tikzpicture}
[every text node part/.style={align=center}]
\begin{scope}[every node/.style={rectangle,draw}]

\node(Chunk) at (0,0) 
{\textbf{Chunk} \\ \small{uid :: String}};

    \node(NamedIdea) at (-3,-1.5) 
    {\textbf{NamedIdea} \\ \small{term :: NounPhrase}};

        \node(Idea) at (-1.5, -3)
		{\textbf{Idea} \\ \small{getA :: Maybe String}};

			\node(Concept) at (0, -4.5)
			{\textbf{Concept} \\ \small{FIXME}};

        \node(CommonIdea) at (-4.5, -3)
        {\textbf{CommonIdea} \\ \small{abrv :: String}};

	\node(ExprRelat) at (0, -1.5)
	{\textbf{ExprRelat} \\ \small{FIXME}};

	\node(Theory) at (2, -1.5)
	{\textbf{Theory} \\ \small{FIXME}};

\node(Definition) at (2.5, 0)
{\textbf{Definition} \\ \small{FIXME}};

\node(ConceptDomain) at (5,0)
{\textbf{ConceptDomain} \\ \small{FIXME}};

%TODO: Finish and make this look nice

\end{scope}

\draw [->] (Chunk.south west) -- (NamedIdea.north east);
\draw [->] (Chunk.south) -- (ExprRelat.north);
\draw [->] (Chunk.south east) -- (Theory.north west);
\draw (NamedIdea) [->] to (CommonIdea);
\draw (NamedIdea) [->] to (Idea);
\draw (Definition) [->, out=330, in=0] to (Concept);
\draw (ConceptDomain) [->, out=270, in=0] to (Concept);
\draw (Idea) [->] to (Concept);

\end{tikzpicture}

%\begin{forest}
%  for tree={
%    align=center,
%    parent anchor=south,
%    child anchor=north,
%    font=\sffamily,
%    edge={thick, -{Stealth[]}},
%    l sep+=10pt,
%    edge path={
%      \noexpand\path [draw, \forestoption{edge}] (!u.parent anchor) -- 
%      +(0,-10pt) -| (.child anchor)\forestoption{edge label};
%    }
%  }
%  [\textbf{Chunk} \\ \small{uid :: String}
%    [\textbf{NamedIdea} \\ \small{term :: NounPhrase}
%      [\textbf{Idea} \\ \small{getA :: Maybe String}]
%      [\textbf{CommonIdea} \\ \small{abrv :: String}]
%    ]
%    [\textbf{Theory} \\ \small{FIXME}]
%    [\textbf{ExprRelat} \\ \small{FIXME}]
%  ]
%  [\textbf{Definition} \\ \small{uid :: String}
%  ]
%\end{forest}
\caption{Chunk hierarchy in Drasil Today}
\label{Fig:ChunkHierarchy}
\end{figure}

When we capture knowledge, we try to encode all of the information surrounding 
that piece of knowledge in an artifact-agnostic manner. We are not concerned 
with which views will be used by our artifacts, only what the underlying 
knowledge is and how it should be captured.

Once we have properly captured the relevant knowledge, we shouldn't have to 
capture it again to reuse it in a different project. Any given piece of 
knowledge should only be added to the knowledge-base once!

\subsection{(Re-)Using Knowledge}
\label{S:KReUse}

Capturing knowledge in itself helps us improve our understanding of the 
underlying theory by laying things out in a structured way. That is a benefit 
in itself, however, when we can actually use the captured knowledge we see many 
advantages to this approach.

The most obvious perk is that we no longer need to manually copy knowledge 
across artifacts, we can simply pull what we need from our knowledge-base. 
While this seems trivial, the ramifications are huge -- we have guaranteed 
consistency by construction. 

At this point you may be wondering, ``what if I want to do more than just copy 
information around?" Recall the example from the beginning of 
Section~\ref{S:KBSE}, the view of our knowledge can change without affecting 
our encoding. To project these views, we use transformations.

Transformations represent the different 'views' of the knowledge we want based 
on how abstract we need it to be, what audience we are targeting, and a host of 
other factors. We use transformations to translate knowledge into its requisite 
forms, whether they be equations, descriptions, code, or something else 
entirely.

We can also use transformations to expose variabilities. These are what define 
project families -- projects which solve the same general problem, but with 
differences in the specific goals and/or implementations of those solutions. 

For example, our case studies (introduced in Section~\ref{S:IntroCases}) for 
SWHS and NoPCM are members of the same \emph{software family} as they solve the 
same general problem with a variation on whether phase-change material is 
present in the system. A correct solution for each problem will look different, 
but there is a non-trivial amount of fundamental knowledge being shared by both 
solutions.

%      - Example: SWHS vs NoPCM
      \fgr{} Show portion of each SRS, one similarity, one difference?

Manually transforming knowledge in this way is tedious and would likely not end 
up cutting costs or saving time. If, on the other hand, we had a framework or 
tool to support the automation of these transformations for our software 
artifacts, those particular disadvantages disappear.

\section{Drasil}
\label{S:Drasil}
- To use KBSE to its potential we need a strong support framework
- Intro to Drasil
    \fgr{} Knowledge tree
  - What it is and does
    - Domain Specific Language(s)
    - Generate all the things!
  - Dev to date.
  - How is Knowledge Capture handled in Drasil? - chunks!
  - What do transformations look like? Recipes!
    \fgr{} SmithEtAl template for SRS = Drasil.DocumentLanguage
  - Key components of the generator / renderer

- Haddock % Drasil is documented -- available on the repo if you make docs.

\subsection{Developing Drasil - A grounded theory} %DS Should this be here or 
													%in bg?
- Following grounded theory (ish). Using data from case studies to guide 
development and implement new features.
- \fgr{}: Before and after System Information.
- \fgr{}: Before and after mini-DBs
- Majority of features developed after analyzing commonalities in the case 
studies and abstracting them out.
- Allows for rapid progress -> constant iteration based on what we find in the 
data.

\subsection{Packaging Drasil}

The current version (0.1.1 as of this writing) of Drasil is built as a 
group of Haskell packages (see Figure~\ref{Fig:Packages}). The core components, 
including those for document generation, are stored in a package named 
\edl{} and code-generation related components are in 
\edc{}. We maintain our current knowledge-base in 
\edd{} and our case study examples in \ede{}.

\begin{figure}
\begin{tikzpicture}

%TODO: Fix this

\node (drasil-lang) [class] {\dl};
\node (drasil-code) [class, below left=1 and 0.2cm of drasil-lang] 
{\dc};
\node (drasil-data) [class, below right=1 and 4cm of drasil-code] {\dd};
\node (drasil-example) [class, below left=1 and 0.54cm of drasil-data] 
{\de};
%lang coords
\coordinate [above=2.785cm of drasil-data] (rightl);
\coordinate [above=1.28cm of drasil-code] (leftl);
%code coords
\coordinate [below=1.25 of drasil-code] (underc);
\coordinate [below left=1.53 and 0.5 of underc] (underleftc);
\coordinate [left=0.5 of drasil-code.south] (leftc);
%data coords
\coordinate [below=1.285 of drasil-data] (underd);

%code
\draw [myarrow] (drasil-code.north) -- (leftl) -- (drasil-lang.west);

%data
\draw [myarrow] (drasil-data.north) -- (rightl) -- (drasil-lang.east);
\draw [myarrow] (drasil-data.west)  -- (underc) -- (drasil-code.south);

%example
\draw [myarrow] (drasil-example.north) -- (drasil-lang);
\draw [myarrow] (drasil-example.west) -- (underleftc) -- (leftc) node[midway, 
left]{depends};
\draw [myarrow] (drasil-example.east) -- (underd) -- (drasil-data.south);

\end{tikzpicture}
\caption{Drasil package dependencies}
\label{Fig:Packages}
\end{figure}

\subsubsection{\dl}

The core language used within the Drasil framework, including all of the 
building blocks for our knowledge-base are stored within \edl{} under the 
exported module \texttt{Language.Drasil}. This package also exports a second 
module with functionality targeted to developers of Drasil known as 
\texttt{Language.Drasil.Development}.

\texttt{Language.Drasil} presently contains the expression DSL, document layout 
DSL, printing DSL, and the generator back-end. Every other \emph{drasil-*} 
package relies on, and builds off, this core. Some of these, notably the 
printing DSL and generator back-end, may be moved to their own packages in the 
near future.

With \texttt{Language.Drasil} alone we can capture knowledge and generate 
artifacts nearly identical to those shown in Section~\ref{S:IntroCases}. 
However this is a much lower-level approach than we would like to use and could 
be seen as being akin to programming in a language like C, or even assembly. 

\subsubsection{\dc}

The code generation DSL used within the Drasil framework is stored here under 
the namespace \texttt{Language.Drasil.Code}. The code generation framework 
incorporates \emph{GOOL}, a Generic Object-Oriented 
Language~\cite{Costabile2012}, to give us the 
ability to target multiple languages -- C++, C\#, Objective C, Java, Lua, and 
Python.

\subsubsection{\dd}

The knowledge-base common to all Drasil programs is curated and maintained 
within this package under the \texttt{Data.Drasil} name. Currently we have 
captured 
knowledge in a range of domains including, but not limited to, Computation, 
Education, Math, Physics, and Software. We have also captured meta-knowledge 
related to documentation, physical properties, and more.

A more detailed breakdown of \texttt{Data.Drasil} will be given in 
Section~\ref{S:Data}.

\subsubsection{\de}

All of the code required to generate artifacts for our case study examples is 
maintained in this one package. Each case study has a unique namespace 
containing everything, other than common knowledge from \edd{}, required to 
generate that particular case study's artifacts. These namespaces can be seen 
in Table~\ref{Tab:Namespaces}. 

\begin{table}
\caption{Case study namespaces in \ede{}}
\label{Tab:Namespaces}
\begin{tabular}[]{ l | l}
		Case Study 		& 				Namespace 						\\
\hline{}
		GlassBR 		& 	\texttt{	Drasil.GlassBR			} 		\\
\hline{}
		GamePhysics 	& 	\texttt{	Drasil.GamePhysics		}	 	\\
\hline{}
		SSP 			& 	\texttt{	Drasil.SSP				}		\\
\hline{}
		SWHS 			& 	\texttt{	Drasil.SWHS				}		\\
\hline{}
		NoPCM 			& 	\texttt{	Drasil.NoPCM			} 		\\
\hline{}
		Tiny 			& 	\texttt{	Drasil.HGHC				} 		\\
\end{tabular}
\end{table}

The \ede{} package also contains an example recipe, found in 
\texttt{Drasil.DocumentLanguage} targeted at recreating the 
SmithEtAl SRS template\cite{SmithEtAl????}. %DS Gotta add the year.
Keeping the recipe with the examples is less than ideal, hence why it will soon 
be moved out of \ede{} and into its own package soon, along with other recipes 
as they are created.
We will discuss the recipe and document language specifics in 
Section~\ref{S:DrasilToday}.

\subsection{Drasil Today}
\label{S:DrasilToday}

- Sentence and Document
- Explain the chunk hierarchy (refer to Section~\ref{S:KnowCapt} figure)
- Data.Drasil
  \fgr{} Knowledge areas we've started to capture (See: SE-CSE paper)
- Recipe Language(s) -- Refer to:
  \fgr{} Drasil.DocumentLanguage
- The generator
  - HTML and TeX rendering
  - GOOL for code
- System Information -> Get into it

\section{Case studies - in more depth}

- Re-introduce case studies
  - Our methods for reimplementing
  - CI for testing
- Start showing off re-use and automated generation.
  - Start with common knowledge (generalized \fgr{}?)
  - Then onto GlassBR example to show off the doc lang recipe (\fgr{}?)
  - Then let's see SRS vs. NoPCM for reuse (particularly NoPCM) (\fgr{}?)

\wss{I like how specific this section is.  You are highlighting specific
  lessons/findings from actual examples.  When you get stuck with writing other
  sections, this would be a good place to focus your energy.  You should be able
  to write this material almost independently of the other sections, at least to
  get started.}

\subsection{Data.Drasil}
\label{S:Data}

- Common knowledge
  \fgr{} SI\_Units
  \fgr{} Thermodynamics (ConsThermE?)

\subsection{GlassBR}

- Brief intro to problem GlassBR is solving - how it works
- Show off the doc language here
  \fgr{} GlassBR SRS in (truncated) DocLang format 
  - "Reads like a table of contents, with a few quirks"
- Show off some code generation
  \fgr{} Side-by-side of Chunk Eqn vs. Doc Eqn vs. Code 
  - "Easy to see that the code matches the equations"
- Talk about potential variabilities and how to make this a family
- Why is this interesting?
	- Fairly straightforward example of something a scientist would create/use 
	in their research

\subsection{NoPCM \& SWHS}

- Re-introduce the problems
- See how they're a family?
- Really drill in the similarities
  \fgr{} Figure showing NoPCM import(s)
- Lots of knowledge-reuse
- Very few 'new' chunks (count them?)
- Show example of variability in action
  \fgr{} Equation with/without PCM (rendered?)
- Why this example is interesting:
  - ODE solver -> We don't gen, just link to existing good one(s)

\subsection{Others}

- Mention SSP, Tiny, GamePhysics, but don't go too in-depth.
  - Useful examples as they give us a wider range of problems for analysis
- Testing
  - Physics is physics -> when we make updates, the underlying knowledge isn't
    changing, so neither should our output
  - Refer to CI

\subsection{Freebies - Compliments of System Information}

- Thanks to the recipe language and the way we structure out system information
  we can get
- Table of Symbols
- Table of Units
- Table of Abbreviations and Acronyms
- Bibliography

- All tedious to do by hand, but are free to automatically generate
- Generator includes sanity-checking -> Can't use something that isn't defined!
- Sanity-checks are 'free' -> we can check for errors with our symbols,
  ensure units are consistent, guard against constraints, and ensure we only
  reference those things which are defined in our system. 
- Sanity-checks are run every time artifacts are generated.

\section{Results}

- Here we discuss the results we've seen so far.
- Had some of these case studies attempted to be certified, they would (should) 
have failed.
	- A number of common problems.

\subsection{Common issues across case studies}

- A number of undefined symbols even after multiple passes by humans. 
(Auto-generating the symbol table and including sanity-checking revealed them)

\subsection{NoPCM and SWHS}

- Along with the common errors, there was some sharing of PCM-related knowledge
  - Found because PCM symbols were not in the ToS and the sanity-check caught 
  it.
  - No way to specifically exclude knowledge that shouldn't 'exist' in a project
- Work in Kolmogorov complexity / MDL for NoPCM + SWHS?
- Kolmogorov/MDL implies less writing for the same artifacts -> less to sift 
through = maybe better?

\subsection{SSP}

- Symbols for given quantities changed throughout the documentation
  - Went unnoticed by a human for years! Found almost instantly by Drasil
    - the new symbols were undefined.

\subsection{Pervasive Bugs}

One of the utmost benefits of the knowledge-based approach using Drasil is the 
introduction of ``pervasive bugs". These are typically mistakes made in the 
captured knowledge which propagate across all generated artifacts wherein that 
knowledge is used. Calling this a benefit may seem counter-intuitive, but when 
an error appears in a multitude of locations it is far more likely to be caught 
then if it were hiding in the corner of one artifact.

Not only is it more likely that we will find an error, it is also far easier to 
track down the source of said error -- we need only go to the knowledge base 
and find the requisite chunk. We can also tune error messages to point us at 
the exact chunk causing the problem if we so desire.

Correcting an error in a chunk of knowledge is also trivial. It only needs to 
be fixed once to be fixed across all of our software artifacts. No need to 
\texttt{grep}, find-and-replace, or the like.


\section{Future Work}

[*SS* - Once we are capable of true variability in the documentation, we can
really start asking the question about what is the "best" documentation for a
given context.  In the future experiments could be done with presenting the same
information in different ways to find which approach is the most effective.]

[*SS* - Related to the previous point, the act of formalizing the knowledge that
goes into the requirements documentation forces us to deeply understand the
distinctions between difference concepts, like scope, goal, theory, assumption,
simplification, etc.  With this knowledge we can improve the focus and
effectiveness of existing templates, and existing requirements solicitation and
analysis efforts.  Teaching it to a computer.]

- Run an experiment to determine how easy it is to create new software with 
Drasil.

- Run an experiment to see how easy it is to find and remove errors with Drasil

- Experiment to see time saved in maintenance while using Drasil vs. not

- Create drasil-gen package

- Design language

- Open issues (as of writing there are \#\#\# %DS 147
issues currently open on the Drasil repository).

\section{Conclusion}

- Easier to find errors (anecdotally) - future work will tell us if this holds.

\bibliography{drasil}
\bibliographystyle{acm}
\end{document}
