\chapter{Results}
\label{c:results}

In this chapter we discuss our observations following the reimplementation 
of our case studies using Drasil. Content here is primarily illustrative: 
concrete examples, issue identifiers, and sample artifacts that document how the
single-source approach affected consistency, traceability, and
reimplementation effort. Formal, controlled experiments are future work
(see Chapter~\ref{c:future}). For interpretation and implications of these
observations, see Chapter~\ref{c:discussion}.

\section{Value in the Mundane}

This section highlights routine, practical benefits that emerged from the
reimplementations. Each subsection focuses on a specific, often-overlooked
advantage \textemdash{} consistency, traceability, and reproducibility 
\textemdash{} and shows how these ``mundane" improvements materially reduce
maintenance effort and increase confidence in generated artifacts.

\subsection{Consistency by Construction}
Drasil's single-source knowledge representation produced artifacts that are
consistent by construction. Small, localized edits to domain knowledge or
recipes propagated deterministically to all generated outputs (documentation
and code). During reimplementations, this property reduced the number of
manual synchronization tasks normally required when maintaining separate
artifacts. In practice, consistency by construction meant that corrections
made in the knowledge base appeared immediately and uniformly across the SRS,
reference tables, and generated code after regeneration.

\subsection{Traceability and Maintainability}
Every generated element (formulas, symbols, tables, code identifiers) can be
traced back to a named knowledge chunk or recipe. The generation pipeline
produces traceability matrices and reference-material tables as part of normal
output, enabling explicit provenance for items that are typically
undocumented. This traceability materially reduced the cognitive effort
required to locate the origin of a definition or relation during maintenance
tasks and refactoring: it was trivial to identify the source to edit rather than
hunting through multiple artifacts.

\subsection{Reproducibility and Determinism}
Artifact generation in Drasil was fully deterministic: repeated generation runs
from the same knowledge base and recipe set produced byte-for-byte equivalent
outputs for the textual artifacts we exercised. Repeatability checks executed
during the case studies confirmed that regenerating artifacts after
environment-consistent builds did not introduce nondeterministic differences,
supporting reproducibility guarantees that are important for scientific
software.

\section{Empirical Evidence: Case Studies and Reimplementations}
We reimplemented each of our case studies using Drasil and recorded
measurable outcomes for generated artifacts and the knowledge source that
produced them.

For the GlassBR case study, the Drasil implementation generated a multi-
page SRS (44 pages in the final PDF) and produced working implementations
in multiple target languages. The complete SRS recipe for GlassBR is
contained in a single source file of under 370 lines of Haskell
(including comments and imports). This line count refers only to the
GlassBR-specific recipe and does not include the shared base knowledge
(units, symbols, common chunks, and generic recipes) that are stored
separately in the global knowledge base and are reused across case studies.

Comparable results were observed for other reimplemented case studies:
each system produced a multi-page SRS and a modest-sized recipe or set of
recipes (tens to a few hundred lines) that captured the system-specific
knowledge. Generated code for each system followed the same pattern:
language-agnostic knowledge encoded as chunks and recipes was emitted to
multiple target languages with consistent identifiers and traceability
annotations.

Generated code and documentation remained consistent after edits to the
knowledge base, with regeneration producing updated artifacts across all
targets.

\subsection{Quality and Bug Detectability}
\label{sec:quality}
Because all artifacts are derived from the same knowledge, a defect in the
knowledge base manifested consistently across every generated artifact. This
property made defects more visible ("pervasive bugs"), which in turn aided
discovery and correction. During reimplementations, categories of problems
that were revealed included inconsistent symbol naming, implicit numeric
constants, and unstated domain assumptions. Fixing those issues at the
knowledge level eliminated their occurrences across documentation and code
simultaneously.

An instructive, concrete example is Issue~\#348 (Slope Stability Problem).
In the original SSP artifacts several closely related symbols (for shear
stress and associated forces) were used inconsistently across sections and
tables. When the SSP content was encoded as Drasil chunks these inconsistencies
became immediately visible: the same semantic item was projected with
conflicting identifiers, and cross-references did not align. Correcting the
underlying chunk in the knowledge base removed the inconsistencies from all
generated artifacts (SRS and code) after regeneration.

\subsection{Design for Change and Software Families}
The single-source approach enabled rapid generation of software-family
variants. Where artifacts differed only by parameterization or small domain
choices (for example, PCM vs NoPCM variants), encoding those choices in the
knowledge base allowed whole-family updates by editing a small set of chunks.
This capability materially reduced the effort to produce consistent variants
of the same artifact family.

\section{Usability and Adoption}
From the reimplementation work it became clear that Drasil's expressiveness
comes with an onboarding cost. Contributors familiar with the codebase could
encode and modify domain knowledge effectively; new users required a
nontrivial ramp-up period to understand the chunk and recipe patterns.
Nevertheless, undergraduate contributors and short-term students were able to
make meaningful contributions after initial mentoring. These observations report
what we observed during reimplementation and are not intended as 
recommendations or required practices.

\section{Summary and Takeaways}
The combined results from the case studies show that the primary benefits of
the Drasil approach are increased consistency, strong provenance for
generated artifacts, and deterministic reproducibility. These benefits
manifested in lower ongoing synchronization effort, higher visibility of
domain assumptions and defects, and faster family-wide changes when those
domain choices were encoded explicitly. The empirical evidence collected
during the reimplementations supports these claims while also documenting the
practical cost of initial knowledge capture and onboarding.

