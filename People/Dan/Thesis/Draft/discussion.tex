\chapter{Discussion}
\label{c:discussion}

This chapter interprets the results reported in Chapter~\ref{c:results}.
We synthesise the practical benefits observed \textemdash{} automation, 
traceability, and rapid adaptation \textemdash{} evaluate costs such as 
onboarding and modelling effort, and outline limitations and directions for 
formal validation. We refer back to observations in Chapter~\ref{c:results} and 
cite illustrative issue examples.

\section{Interpreting the Results}

This section organises the principal outcomes from
Chapter~\ref{c:results} into interpretation themes that mirror the
observations: consistency, traceability, reproducibility, and the
tradeoffs that follow from centralizing knowledge.

\subsection{Consistency by construction}

Drasil projects a single knowledge base into diverse artifacts. The case
studies demonstrate that local changes to domain knowledge yield system-wide
corrections. Practically, this reduces the maintenance surface area: a
single canonical edit replaces repeated, artifact-level fixes. The primary
tradeoff is increased upfront modelling effort and the need for disciplined
knowledge capture.

Disciplined knowledge capture also forces clarification of implicit assumptions
that would otherwise lead to inconsistencies. For example, in the \sp{} case
study (Issue \#348, Section~\ref{sec:quality}), inconsistent symbol naming
across the original artifacts led to confusion and errors in equations. These 
were only caught after careful review during reimplementation. Encoding the 
symbols as Drasil chunks enforced a single canonical name and identifier, 
eliminating the inconsistencies across all generated artifacts.

Similarly, as we are forced to encode all domain knowledge explicitly in 
Drasil, it is impossible to end up in a situation where we have undefined 
symbols or equations that reference missing quantities. A concrete example of 
this was discovered while investigating the same issue mentioned above (issue 
\#348), where during reimplementation we discovered the symbol $\tau_i$ was 
used in equations in the original SRS, but did not appear in the table of 
symbols or have a formal definition. When encoding the knowledge in Drasil, we 
had to define these symbols explicitly as chunks, which ensured that they were 
properly documented in the generated SRS and correctly referenced in the 
generated code.

A further benefit of this approach is that several supporting sections, such as 
the many tables in the Reference Materials section of the SRS as well as the 
traceability matrices, are generated automatically from the structure of the 
knowledge in use. These sections, which are often neglected or inconsistently 
maintained in traditional workflows (as per the issue mentioned above), are 
kept up to date ``for free" as a consequence of Drasil's single-source 
knowledge capture, further reinforcing consistency and reducing manual effort.

\subsection{Traceability and refactoring}

Centralized knowledge makes provenance explicit: formulas, symbols, and
identifiers trace back to named chunks or recipes. That provenance eases
refactoring because changes localized to chunks produce immediate updates
across downstream artifacts. The recipe DSL allows reorganizing output
structures (documentation sections, code modules, etc.) without manual edits
to each target artifact.

A key advantage of Drasil's architecture is the separation of concerns between
knowledge and presentation. The structure of generated artifacts can be
modified (``on the fly") by changing recipes, without altering the underlying 
knowledge base. For example, generated code can be adapted to include features like logging
by updating code generation recipes alone. This enhances maintainability,
traceability, and adaptability of the generated artifacts.

Drasil also supports the systematic evolution of software families. By
separating domain knowledge from artifact-specific recipes, Drasil enables
controlled introduction of variation points. New family members can be
generated by modifying recipes or selectively extending the knowledge base,
rather than duplicating and manually editing artifacts. This reduces the risk
of divergence and inconsistency among related products.

A concrete example is seen in the development of the \sw{} and \np{} case
studies (see Section~\ref{sec:design_change} for related results). 
Both are members of the same software family, sharing core physical
concepts and requirements but differing in specific details. Because the
fundamental knowledge was already encoded for \sw{}, creating \np{} required
only targeted extensions and modifications to existing chunks and recipes.
This reuse minimized duplication, ensured consistency across both projects,
and allowed rapid adaptation of documentation and code for \np{}. The shared
knowledge base made it straightforward to propagate improvements or
corrections from one family member to the other, further demonstrating the
advantages of Drasil's approach for software families.

When adapting a requirements specification for a new variant, contributors
can introduce new chunks or adjust parameters in the knowledge base, while
reusing existing recipes to maintain structure and traceability.
Alternatively, recipes can be specialized to produce tailored documentation
or code modules for specific family members, all while referencing the same
core knowledge. This design for change streamlines the creation and
maintenance of software families, and supports rapid, reliable adaptation to
evolving requirements.

\subsection{Reproducibility and error visibility}
\label{sec:dis_reproducibility}
Artifact generation was deterministic in our case studies: regenerating from
the same knowledge base produced consistent textual outputs. At the same
time, defects in the knowledge base appear across all generated artifacts,
which increases visibility and simplifies root-cause correction.

Recall Issue \#348 from \sp{} mentioned in Section~\ref{sec:quality}. To 
summarize, the issue was that some closely related symbols had their uses mixed 
up in several places in the original case study. In more detail, the \sp{} 
inconsistencies manifested in three concrete ways:
\begin{enumerate}
\item Multiple names and short identifiers for the same physical quantity 
across equations and tables.
\item Implicit or mismatched units appearing in different tables.
\item References and captions that used variant labels, breaking 
cross-references.
\end{enumerate}

Encoding the \sp{} concepts as chunks forced a 
single canonical name, an explicit unit declaration, and a
consistent label for each concept that could not get switched to a different 
symbol.

Using Drasil, the remediation followed a small, local workflow: identify the 
semantic chunk representing the quantity, unify the identifier and unit within 
that chunk, and regenerate. The result was immediate and verifiable: the SRS,
tables, and generated code all used the same identifier and unit, table
cross-references resolved, and no further manual edits were necessary. This 
example illustrates how centralized knowledge surfacing both increases error 
visibility and enables concise, single-point fixes.

\section{Human Factors and Usability}

Experienced contributors adapted quickly to Drasil's patterns, but new users
found the knowledge-capture DSL challenging. Two priorities emerge: improved
discovery and search tools for the knowledge base, and higher-level authoring
interfaces that present domain concepts in more familiar terms. In short: 
Drasil desperately needs better tooling for authoring.

\section{Limitations and Directions for Validation}

The current evidence is largely qualitative and anecdotal. Formal,
controlled experiments are required to measure productivity gains,
maintenance cost reduction, and error rates across larger teams. Until such
studies are performed, claims about absolute gains should be framed as
preliminary.

Future validation should include controlled studies measuring onboarding 
metrics (time to first meaningful edit, amount of mentoring required),
maintenance effort, and error rates across teams of varying experience. Experimental designs could compare Drasil-based workflows to traditional manual approaches, quantifying differences in initial productivity, long-term maintenance, and defect reduction. These metrics will be essential for substantiating the qualitative benefits observed in this thesis. Feedback from such studies will also guide the development of improved authoring tools and onboarding resources, helping to lower the initial ramp-up cost and make Drasil accessible to a broader range of users.

Scalability concerns also merit attention: as the knowledge base grows,
improved tools for discovery, efficient projection, and modularization will
be essential to maintain developer productivity.

\section{Lessons Learned}

\begin{enumerate}
\item Many dangerous inconsistencies in legacy artifacts trace back to tacit
  assumptions and implicit knowledge during requirements capture; making
  those assumptions explicit in chunks forces clarification and improves 
  both maintainability and traceability.
\item Drasil's architecture shifts the correctness burden from artifact authors 
  to knowledge-base modelers: this trades repeated artifact-level maintenance
  for concentrated, knowledge-level review.
\item Rapid case-study reimplementation and ease of propagation suggest the
  approach can scale across domains given improved onboarding and
  validation, provided the domain knowledge can be effectively captured.
\item The recipe DSL enables flexible artifact structuring and adaptation without
  modifying the underlying knowledge, supporting maintainability and
  evolution.
\item Centralized knowledge capture increases error visibility by making defects
  pervasive across all generated artifacts, simplifying root-cause analysis
  and correction.
\item The single-source approach facilitates rapid generation of software-family
  variants by enabling controlled introduction of variation points in the
  knowledge base and recipes, reducing duplication and ensuring consistency
  across related products.
\item Improved authoring tools and onboarding processes are critical to lower
  the initial ramp-up cost and make Drasil accessible to a broader range of
  users.
\item Formal, controlled studies are needed to quantify productivity gains,
  maintenance cost reductions, and error rates to validate the qualitative
  observations reported here.
\item Deterministic, automated artifact generation supports scientific reproducibility by 
  ensuring that repeated builds from the same knowledge base yield identical outputs, reducing 
  the risk of accidental divergence and increasing confidence in results.
\item Centralized, structured knowledge enables the automatic generation and consistent 
  maintenance of supporting materials—such as traceability matrices and reference tables—that 
  are often neglected or inconsistently updated in traditional workflows.
\item The development and reporting of quantitative metrics—such as onboarding time, 
  regeneration timings, and maintenance effort—are essential for guiding future improvements 
  and validating the practical impact of the approach.
\item Drasil's extensible architecture allows it to adapt to new requirements and scientific 
  advances by incorporating richer or more abstract domain knowledge, future-proofing the 
  system as knowledge capture mechanisms evolve.
\end{enumerate}

\section{Summary and Takeaways}

Drasil's single-source approach delivers several practical benefits. Consistency
is enforced by projecting a single knowledge base into all artifacts, ensuring
that local edits yield system-wide corrections and eliminating inconsistencies
common in manual workflows. Traceability is improved, as provenance for formulas,
symbols, and requirements is explicit and changes are automatically propagated
across documentation and code. Reproducibility is enhanced by automating artifact
generation, reducing the risk of human error and ensuring that supporting
materials such as traceability matrices and reference tables are always
up-to-date.

Automation further reduces manual effort, especially when generating new projects
or adapting existing ones. Boilerplate text and artifact structure are handled by
recipes, allowing contributors to focus on encoding domain knowledge. This
approach also supports the systematic evolution of software families: new
variants can be created by extending the knowledge base or modifying recipes,
minimizing duplication and maintaining consistency across related products.

The primary tradeoff is increased upfront modeling and onboarding effort. The
benefits of Drasil's approach are most pronounced when a substantial portion of
domain knowledge can be reused, but even in new projects, the reduction in
manual duplication and the gains in maintainability are significant. Continued
investment in authoring tools and onboarding resources will help lower the
initial ramp-up cost.

Drasil is designed for extensibility. As our mechanisms for knowledge capture
improve, we will be able to encode more fundamental domain concepts and extend
the scope of the knowledge base. This extensibility means Drasil can adapt to
new requirements or scientific advances by incorporating richer or more abstract
representations, rather than requiring a redesign of the system. Continued
improvement of knowledge capture tooling and methodologies will directly
increase the breadth and depth of what Drasil can represent and generate,
further amplifying its benefits for consistency, traceability, and automation.

The observations in Chapter~\ref{c:results} support these conclusions and point
to concrete next steps: measure onboarding overhead, report regeneration
timings, and develop discovery and authoring tools to reduce the initial
ramp-up. Drasil's architecture positions it well for future growth as both a
research platform and a practical tool for reliable, maintainable scientific
software.
